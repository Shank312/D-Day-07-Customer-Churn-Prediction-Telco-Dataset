ğŸ“Š Customer Churn Prediction (Telco Dataset)

This project predicts customer churn for a telecom company using machine learning models.
The dataset contains customer demographics, services, contract details, and billing information.
The goal is to predict whether a customer will churn (leave) or stay.


ğŸš€ Project Workflow

Load Dataset

CSV: Telco_customer_churn.csv

Handled using pandas.

Preprocessing

Dropped non-informative columns (CustomerID, redundant churn columns).

Converted Total Charges to numeric.

Encoded target column Churn â†’ (Yes=1, No=0).

One-hot encoded categorical columns.

Final dataset: 7043 customers Ã— 2816 features.

Train-Test Split

80% training, 20% testing.

Stratified split to preserve churn ratio.

Models Trained

Logistic Regression (baseline linear classifier).

Random Forest (ensemble of decision trees).

XGBoost (boosting algorithm, high performance).

Evaluation Metrics

Precision â†’ How many predicted churners are real churners.

Recall â†’ How many real churners are caught.

F1-Score â†’ Balance between precision & recall.

| Model               | Precision | Recall | F1 Score |
| ------------------- | --------- | ------ | -------- |
| Logistic Regression | 0.836     | 0.845  | 0.840    |
| Random Forest       | 0.896     | 0.805  | 0.848    |
| XGBoost             | 0.851     | 0.872  | 0.861    |


âœ… XGBoost performed best.

Save Model

Best model saved as: churn_model.pkl (using joblib).


ğŸ“‚ Project Structure
03_customer_churn/
â”‚â”€â”€ data_loader.py          # Load dataset
â”‚â”€â”€ preprocess.py           # Preprocess categorical & numerical features
â”‚â”€â”€ data_splitter.py        # Train-test split
â”‚â”€â”€ logistic_trainer.py     # Train Logistic Regression
â”‚â”€â”€ random_forest_trainer.py# Train Random Forest
â”‚â”€â”€ xgboost_trainer.py      # Train XGBoost
â”‚â”€â”€ evaluator.py            # Evaluate models (Precision, Recall, F1)
â”‚â”€â”€ model_exporter.py       # Save trained model
â”‚â”€â”€ main.py                 # Full pipeline runner
â”‚â”€â”€ churn_model.pkl         # Saved best model (XGBoost)
â”‚â”€â”€ Telco_customer_churn.csv# Dataset
â”‚â”€â”€ README.md               # Project documentation



âš¡ How to Run

Clone repository or open project folder.

Install dependencies:
pip install pandas numpy scikit-learn xgboost joblib

Run full pipeline:
python main.py


ğŸ¯ Key Learnings

Churn prediction is critical for customer retention in telecom.

XGBoost outperforms traditional models for churn.

Precision/Recall trade-off matters more than accuracy for imbalanced data.


ğŸ”® Next Steps

Feature importance analysis (which features drive churn).

Hyperparameter tuning for XGBoost.

Handle class imbalance (SMOTE, class weights).

Deploy model as an API (Flask/FastAPI).


ğŸ‘¨â€ğŸ’» Author: Shankar Kumar
ğŸ“Œ AI/ML Mastery Path â€” Day 07 Project
